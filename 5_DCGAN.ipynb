{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5.DCGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNuVOtgHMWx/UQfMBesybQc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gkrry2723/ML_pytorch_study/blob/master/5_DCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHAga8AMoUU0"
      },
      "source": [
        "1. 데이터 준비\n",
        "- 꽃 데이터\n",
        "- 102 종류의 꽃을 약 8000장의 이미지 데이터로 제공"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPrgHldQoNjp",
        "outputId": "ce3cbcba-1039-4641-c3d6-817272ec39de"
      },
      "source": [
        "!wget http://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz\n",
        "!tar xf 102flowers.tgz\n",
        "!mkdir oxford-102\n",
        "!mkdir oxford-102/jpg\n",
        "!mv jpg/*.jpg oxford-102/jpg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-14 08:39:59--  http://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz\n",
            "Resolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\n",
            "Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz [following]\n",
            "--2021-05-14 08:39:59--  https://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz\n",
            "Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 344862509 (329M) [application/x-gzip]\n",
            "Saving to: ‘102flowers.tgz’\n",
            "\n",
            "102flowers.tgz      100%[===================>] 328.89M  21.9MB/s    in 16s     \n",
            "\n",
            "2021-05-14 08:40:15 (20.8 MB/s) - ‘102flowers.tgz’ saved [344862509/344862509]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVGdXempv8ym"
      },
      "source": [
        "2. data loader만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiGUodtmqQli"
      },
      "source": [
        "import torch\n",
        "from torch import nn,optim\n",
        "from torch.utils.data import (Dataset,DataLoader,TensorDataset)\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "\n",
        "img_data = ImageFolder(\"/content/oxford-102/\", transform = transforms.Compose([transforms.Resize(80), transforms.CenterCrop(64),transforms.ToTensor()]))\n",
        "\n",
        "batch_size = 64\n",
        "img_loader = DataLoader(img_data,batch_size = batch_size, shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58kP3P2zv-mj"
      },
      "source": [
        "3. net 만들기\n",
        "\n",
        "생성모델    z : 100차원 -> 3* 64 * 64\n",
        "식별모델    image : 3* 64 * 64 -> 1차원 스칼라"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhwdAH7vv6qg"
      },
      "source": [
        "nz = 100\n",
        "ngf = 32\n",
        "\n",
        "#생성 모델\n",
        "class GNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.main = nn.Sequential(\n",
        "        nn.ConvTranspose2d(nz,ngf*8,4,1,0,bias=False),\n",
        "        nn.BatchNorm2d(ngf*8),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        nn.ConvTranspose2d(ngf*8,ngf*4,4,2,1,bias=False),\n",
        "        nn.BatchNorm2d(ngf*4),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        nn.ConvTranspose2d(ngf*4,ngf*2,4,2,1,bias=False),\n",
        "        nn.BatchNorm2d(ngf*2),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        nn.ConvTranspose2d(ngf*2,ngf,4,2,1,bias=False),\n",
        "        nn.BatchNorm2d(ngf),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        nn.ConvTranspose2d(ngf,3,4,2,1,bias=False),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = self.main(x)\n",
        "    return out\n",
        "\n",
        "\n",
        "#식별 모델\n",
        "ndf = 32\n",
        "class DNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.main = nn.Sequential(\n",
        "        nn.Conv2d(3,ndf,4,2,1,bias=False),\n",
        "        nn.LeakyReLU(0.2,inplace=True),\n",
        "        \n",
        "        nn.Conv2d(ndf,ndf*2,4,2,1,bias=False),\n",
        "        nn.BatchNorm2d(ndf*2),\n",
        "        nn.LeakyReLU(0.2,inplace=True),\n",
        "        \n",
        "        nn.Conv2d(ndf*2,ndf*4,4,2,1,bias=False),\n",
        "        nn.BatchNorm2d(ndf*4),\n",
        "        nn.LeakyReLU(0.2,inplace=True),\n",
        "\n",
        "        nn.Conv2d(ndf*4,ndf*8,4,2,1,bias=False),\n",
        "        nn.BatchNorm2d(ndf*8),\n",
        "        nn.LeakyReLU(0.2,inplace=True),\n",
        "\n",
        "        nn.Conv2d(ndf*8, 1, 4,1,0,bias=False)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = self.main(x)\n",
        "    return out.squeeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjlOvGfi3B1Z"
      },
      "source": [
        "4. 훈련 함수 작성\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HparrCeo3EO-"
      },
      "source": [
        "d = DNet().to(\"cuda:0\")\n",
        "g = GNet().to(\"cuda:0\")\n",
        "\n",
        "opt_d = optim.Adam(d.parameters(), lr = 0.0002, betas=(0.5,0.999))\n",
        "opt_g = optim.Adam(g.parameters(), lr=0.0002, betas=(0.5,0.999))\n",
        "\n",
        "# ce 계산하기 위한 보조변수들 \n",
        "ones = torch.ones(batch_size).to(\"cuda:0\")\n",
        "zeros = torch.zeros(batch_size).to(\"cuda:0\")\n",
        "loss_f=nn.BCEWithLogitsLoss()\n",
        "\n",
        "# 모니터링용 z\n",
        "fixed_z= torch.randn(batch_size,nz,1,1).to(\"cuda:0\")\n",
        "\n",
        "# 훈련함수\n",
        "from statistics import mean\n",
        "import tqdm\n",
        "\n",
        "def train_dcgan(g,d,opt_g,opt_d,loader):\n",
        "  log_loss_g=[]\n",
        "  log_loss_d=[]\n",
        "  for real_img, _ in tqdm.tqdm(loader):\n",
        "    batch_len = len(real_img)\n",
        "\n",
        "    real_img = real_img.to(\"cuda:0\")\n",
        "\n",
        "    #가짜 이미지 만들기\n",
        "    z = torch.randn(batch_len,nz,1,1).to(\"cuda:0\")\n",
        "    fake_img = g(z)\n",
        "\n",
        "    # g 갱신하고 d 갱신관련 할건데 g 갱신하고나면 fake_img의 파라메터도 막 바뀌니까 일단 저장해놓기\n",
        "    fake_img_tensor = fake_img.detach()\n",
        "\n",
        "    #가짜이미지의 평가함수 계산\n",
        "    out = d(fake_img)\n",
        "\n",
        "    # 생성 모델 업데이트\n",
        "    # 가짜 이미지에 대한 d의 평가와 1(진짜)를 크로스엔트로피.\n",
        "    # 가짜이미지가 더 진짜같아 질수록 해당 크로스엔트로피는 점점 줄어듦\n",
        "    loss_g = loss_f(out,ones[:batch_len])\n",
        "    log_loss_g.append(loss_g.item())\n",
        "\n",
        "    d.zero_grad()\n",
        "    g.zero_grad()\n",
        "    loss_g.backward()\n",
        "    opt_g.step()\n",
        "\n",
        "    # 식별모델\n",
        "    real_out = d(real_img)\n",
        "    loss_d_real = loss_f(real_out,ones[:batch_len])\n",
        "    fake_img = fake_img_tensor\n",
        "    fake_out = d(fake_img_tensor)\n",
        "    loss_d_fake = loss_f(fake_out,zeros[:batch_len])\n",
        "\n",
        "    # discriminator 의 loss는 real 의 로스와 fake 의 로스를 합한거임..!\n",
        "    loss_d = loss_d_real + loss_d_fake\n",
        "    log_loss_d.append(loss_d.item())\n",
        "\n",
        "    # 식별 모델의 미분 계산과 파라미터 갱신\n",
        "    d.zero_grad()\n",
        "    g.zero_grad()\n",
        "    loss_d.backward()\n",
        "    opt_d.step()\n",
        "\n",
        "  return mean(log_loss_g), mean(log_loss_d)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Si01R5-A65xJ"
      },
      "source": [
        "5. 훈련하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ia_x1KrU68Rp",
        "outputId": "b1fa7679-ce60-48d9-c87e-7bcff1d25a13"
      },
      "source": [
        "from torchvision.utils import save_image\n",
        "\n",
        "for epoch in range(300):\n",
        "  train_dcgan(g,d,opt_g,opt_d,img_loader)\n",
        "\n",
        "  #10회 반복마다 학습 결과 저장\n",
        "  if epoch%10 == 0:\n",
        "    #파라미터 저장\n",
        "    torch.save(\n",
        "        g.state_dict(),\n",
        "        \"/content/g_{:03d}.prm\".format(epoch),\n",
        "        pickle_protocol=4)\n",
        "    \n",
        "    torch.save(\n",
        "        d.state_dict(),\n",
        "        \"/content/d_{:03d}.prm\".format(epoch),\n",
        "        pickle_protocol=4)\n",
        "    \n",
        "    # 모니터링용 z로부터 생성한 이미지 저장\n",
        "    generated_img = g(fixed_z)\n",
        "    save_image(generated_img, \"/content/{:03d}.jpg\".format(epoch))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:54<00:00,  2.36it/s]\n",
            "100%|██████████| 128/128 [00:53<00:00,  2.39it/s]\n",
            "100%|██████████| 128/128 [00:53<00:00,  2.38it/s]\n",
            "100%|██████████| 128/128 [00:53<00:00,  2.38it/s]\n",
            "100%|██████████| 128/128 [00:53<00:00,  2.39it/s]\n",
            "100%|██████████| 128/128 [00:53<00:00,  2.38it/s]\n",
            "100%|██████████| 128/128 [00:53<00:00,  2.40it/s]\n",
            "100%|██████████| 128/128 [00:53<00:00,  2.38it/s]\n",
            "100%|██████████| 128/128 [00:53<00:00,  2.38it/s]\n",
            "100%|██████████| 128/128 [00:53<00:00,  2.41it/s]\n",
            "100%|██████████| 128/128 [00:53<00:00,  2.40it/s]\n",
            "100%|██████████| 128/128 [00:53<00:00,  2.41it/s]\n",
            "100%|██████████| 128/128 [00:53<00:00,  2.40it/s]\n",
            "100%|██████████| 128/128 [00:53<00:00,  2.38it/s]\n",
            "100%|██████████| 128/128 [00:53<00:00,  2.39it/s]\n",
            "100%|██████████| 128/128 [00:53<00:00,  2.38it/s]\n",
            "100%|██████████| 128/128 [00:53<00:00,  2.38it/s]\n",
            "100%|██████████| 128/128 [00:53<00:00,  2.41it/s]\n",
            "100%|██████████| 128/128 [00:53<00:00,  2.39it/s]\n",
            "100%|██████████| 128/128 [00:53<00:00,  2.38it/s]\n",
            "100%|██████████| 128/128 [00:53<00:00,  2.38it/s]\n",
            " 91%|█████████ | 116/128 [00:48<00:05,  2.40it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao4g_ijV7jjJ"
      },
      "source": [
        "from IPython.display import Image,display_jpeg\n",
        "display_jpeg(Image('/content/000.jpg'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}